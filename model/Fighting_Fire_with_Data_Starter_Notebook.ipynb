{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2lLzfdilxfsY"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt \n",
        "from yellowbrick.model_selection import RFECV\n",
        "from sklearn.feature_selection import RFE, RFECV\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from scipy.stats import boxcox, yeojohnson\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "uaQM7lJHxRoe",
        "outputId": "c1992756-e707-443b-b85b-0289d670ec34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((83148, 29), (25584, 28))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The training data.\n",
        "train = pd.read_csv('../data/Train.csv')\n",
        "test = pd.read_csv('../data/Test.csv')\n",
        "ss = pd.read_csv('../data/SampleSubmission.csv')\n",
        "train.shape, test.shape\n",
        "\n",
        "\n",
        "# // The training data has many features so that could lead to a curse of dimensionality \n",
        "    # // dimentionality reduction - PCA and other methods\n",
        "    # // feature selection for importance features ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "burn_area\n"
          ]
        }
      ],
      "source": [
        "# // only the target is not present in the testing set\n",
        "\n",
        "for column in train.columns:\n",
        "    if column not in test.columns:\n",
        "        print(column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(False, False, False)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# // Investigate missing values\n",
        "    # // There are no missing values\n",
        "\n",
        "train.isnull().any().any(), test.isnull().any().any(), ss.isnull().any().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1WCG4h0-S_v1",
        "outputId": "ce07db1b-78b5-48f7-fe5f-56a74699589d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>burn_area</th>\n",
              "      <th>climate_aet</th>\n",
              "      <th>climate_def</th>\n",
              "      <th>climate_pdsi</th>\n",
              "      <th>climate_pet</th>\n",
              "      <th>climate_pr</th>\n",
              "      <th>climate_ro</th>\n",
              "      <th>climate_soil</th>\n",
              "      <th>...</th>\n",
              "      <th>landcover_0</th>\n",
              "      <th>landcover_1</th>\n",
              "      <th>landcover_2</th>\n",
              "      <th>landcover_3</th>\n",
              "      <th>landcover_4</th>\n",
              "      <th>landcover_5</th>\n",
              "      <th>landcover_6</th>\n",
              "      <th>landcover_7</th>\n",
              "      <th>landcover_8</th>\n",
              "      <th>precipitation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>8.314800e+04</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "      <td>83148.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-19.014557</td>\n",
              "      <td>29.860856</td>\n",
              "      <td>0.007632</td>\n",
              "      <td>484.491124</td>\n",
              "      <td>828.892721</td>\n",
              "      <td>-30.806237</td>\n",
              "      <td>1313.382992</td>\n",
              "      <td>54.576322</td>\n",
              "      <td>6.215134</td>\n",
              "      <td>305.477919</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006158</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.008583</td>\n",
              "      <td>4.066313e-08</td>\n",
              "      <td>0.160628</td>\n",
              "      <td>0.037453</td>\n",
              "      <td>0.785382</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>0.078551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.588444</td>\n",
              "      <td>1.751090</td>\n",
              "      <td>0.029226</td>\n",
              "      <td>470.467480</td>\n",
              "      <td>546.934469</td>\n",
              "      <td>235.802930</td>\n",
              "      <td>315.209838</td>\n",
              "      <td>71.997561</td>\n",
              "      <td>21.480399</td>\n",
              "      <td>400.956123</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053111</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.059046</td>\n",
              "      <td>3.535121e-06</td>\n",
              "      <td>0.192957</td>\n",
              "      <td>0.106050</td>\n",
              "      <td>0.233953</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.014233</td>\n",
              "      <td>0.104464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-22.358835</td>\n",
              "      <td>25.487029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-563.000000</td>\n",
              "      <td>587.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-20.358835</td>\n",
              "      <td>28.487029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>375.000000</td>\n",
              "      <td>-212.000000</td>\n",
              "      <td>1081.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.014993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-18.858835</td>\n",
              "      <td>29.987029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>302.000000</td>\n",
              "      <td>858.000000</td>\n",
              "      <td>-108.000000</td>\n",
              "      <td>1290.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.076706</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.880600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-17.858835</td>\n",
              "      <td>31.237029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>931.000000</td>\n",
              "      <td>1211.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>1517.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>329.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.246498</td>\n",
              "      <td>0.015166</td>\n",
              "      <td>0.971209</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-15.858835</td>\n",
              "      <td>32.987029</td>\n",
              "      <td>0.843886</td>\n",
              "      <td>1713.000000</td>\n",
              "      <td>2614.000000</td>\n",
              "      <td>851.000000</td>\n",
              "      <td>2620.000000</td>\n",
              "      <td>501.000000</td>\n",
              "      <td>342.000000</td>\n",
              "      <td>3319.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.828131</td>\n",
              "      <td>0.004918</td>\n",
              "      <td>0.711603</td>\n",
              "      <td>3.073689e-04</td>\n",
              "      <td>0.981472</td>\n",
              "      <td>0.881323</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.016708</td>\n",
              "      <td>0.301823</td>\n",
              "      <td>0.801328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                lat           lon     burn_area   climate_aet   climate_def  \\\n",
              "count  83148.000000  83148.000000  83148.000000  83148.000000  83148.000000   \n",
              "mean     -19.014557     29.860856      0.007632    484.491124    828.892721   \n",
              "std        1.588444      1.751090      0.029226    470.467480    546.934469   \n",
              "min      -22.358835     25.487029      0.000000      0.000000      0.000000   \n",
              "25%      -20.358835     28.487029      0.000000     50.000000    375.000000   \n",
              "50%      -18.858835     29.987029      0.000000    302.000000    858.000000   \n",
              "75%      -17.858835     31.237029      0.000000    931.000000   1211.000000   \n",
              "max      -15.858835     32.987029      0.843886   1713.000000   2614.000000   \n",
              "\n",
              "       climate_pdsi   climate_pet    climate_pr    climate_ro  climate_soil  \\\n",
              "count  83148.000000  83148.000000  83148.000000  83148.000000  83148.000000   \n",
              "mean     -30.806237   1313.382992     54.576322      6.215134    305.477919   \n",
              "std      235.802930    315.209838     71.997561     21.480399    400.956123   \n",
              "min     -563.000000    587.000000      0.000000      0.000000      1.000000   \n",
              "25%     -212.000000   1081.000000      1.000000      0.000000     70.000000   \n",
              "50%     -108.000000   1290.000000     22.000000      1.000000    149.000000   \n",
              "75%      142.000000   1517.000000     87.000000      4.000000    329.000000   \n",
              "max      851.000000   2620.000000    501.000000    342.000000   3319.000000   \n",
              "\n",
              "       ...   landcover_0   landcover_1   landcover_2   landcover_3  \\\n",
              "count  ...  83148.000000  83148.000000  83148.000000  8.314800e+04   \n",
              "mean   ...      0.006158      0.000017      0.008583  4.066313e-08   \n",
              "std    ...      0.053111      0.000141      0.059046  3.535121e-06   \n",
              "min    ...      0.000000      0.000000      0.000000  0.000000e+00   \n",
              "25%    ...      0.000000      0.000000      0.000000  0.000000e+00   \n",
              "50%    ...      0.000000      0.000000      0.000000  0.000000e+00   \n",
              "75%    ...      0.000000      0.000000      0.000000  0.000000e+00   \n",
              "max    ...      0.828131      0.004918      0.711603  3.073689e-04   \n",
              "\n",
              "        landcover_4   landcover_5   landcover_6   landcover_7   landcover_8  \\\n",
              "count  83148.000000  83148.000000  83148.000000  83148.000000  83148.000000   \n",
              "mean       0.160628      0.037453      0.785382      0.000354      0.001424   \n",
              "std        0.192957      0.106050      0.233953      0.001773      0.014233   \n",
              "min        0.000000      0.000000      0.000019      0.000000      0.000000   \n",
              "25%        0.014993      0.000000      0.655322      0.000000      0.000000   \n",
              "50%        0.076706      0.000139      0.880600      0.000000      0.000000   \n",
              "75%        0.246498      0.015166      0.971209      0.000000      0.000000   \n",
              "max        0.981472      0.881323      1.000000      0.016708      0.301823   \n",
              "\n",
              "       precipitation  \n",
              "count   83148.000000  \n",
              "mean        0.078551  \n",
              "std         0.104464  \n",
              "min         0.000000  \n",
              "25%         0.002017  \n",
              "50%         0.028503  \n",
              "75%         0.125500  \n",
              "max         0.801328  \n",
              "\n",
              "[8 rows x 28 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at distribution of each variable\n",
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.675599412401078\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1300x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# // The target is highly skewed\n",
        "    # // we need to transform it\n",
        "\n",
        "print(train.burn_area.skew())\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize = (13, 7))\n",
        "sns.histplot(train.burn_area)\n",
        "plt.title('household_size variable distribution', y = 1.02, fontsize = 15)\n",
        "display(plt.show())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "eF2NXmXbSOaW",
        "outputId": "6ac88e20-9ef9-4602-84ab-0f2bae1d276b"
      },
      "outputs": [],
      "source": [
        "# Look at correlation with target\n",
        "train.select_dtypes(include=['number']).corr()['burn_area'].sort_values().plot(kind='bar', figsize=(18, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXIk62X9iONj"
      },
      "source": [
        "##  Adding date features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pn-SKQxiHAon"
      },
      "outputs": [],
      "source": [
        "# Split the ID (eg 127_2017-01-03) to get the date string, which we convert to datetime to make life easier\n",
        "train['date'] = pd.to_datetime(train['ID'].apply(lambda x: x.split('_')[1]))\n",
        "test['date'] = pd.to_datetime(test['ID'].apply(lambda x: x.split('_')[1]))\n",
        "train['burn_area'] = pd.to_numeric(train['burn_area'], errors='coerce')\n",
        "\n",
        "\n",
        "# Date variables\n",
        "train['month'] = train.date.dt.month\n",
        "train['year'] = train.date.dt.year\n",
        "train['day'] = train.date.dt.weekday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# // Discretization\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "def optimal_k(data: pd.DataFrame, column: str, max_k: int=10):\n",
        "    silhouette_scores = []\n",
        "    X = data[column].values.reshape(-1, 1)\n",
        "    for k in range(2, max_k+1):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(X)\n",
        "        score = silhouette_score(X, kmeans.labels_)\n",
        "        silhouette_scores.append(score)\n",
        "        optimal_k = range(2, max_k+1)[silhouette_scores.index(max(silhouette_scores))]\n",
        "    return optimal_k\n",
        "\n",
        "\n",
        "def binning(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    numerics = []\n",
        "    for i in data.columns:\n",
        "        if data[i].dtype == 'float' or data[i].dtype == 'int':\n",
        "            numerics.append(i)\n",
        "\n",
        "    for column in numerics:\n",
        "        k = optimal_k(data, column)\n",
        "        reshaped_data = data[column].values.reshape(-1, 1)\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        data[column] = kmeans.fit_predict(reshaped_data)\n",
        "    return data\n",
        "\n",
        "\n",
        "train = binning(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# // Handling outliers\n",
        "    # // find other methods as well\n",
        "\n",
        "\n",
        "def capping(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    numerics = []\n",
        "    for col in data.columns:\n",
        "        if data[col].dtype == 'float' or data[col].dtype == 'int':\n",
        "            numerics.append(col)\n",
        "\n",
        "    for col in numerics:\n",
        "        q1 = data[col].quantile(0.25)\n",
        "        q2 = data[col].quantile(0.75)\n",
        "        iqr = q2 - q1\n",
        "        max_limit = q2 + (1.5 * iqr)\n",
        "        min_limit = q1 - (1.5 * iqr)\n",
        "        data[col]  = pd.DataFrame(\n",
        "            np.where(data[col] > max_limit, max_limit,\n",
        "            (np.where(data[col] < min_limit, min_limit, data[col]))), columns=[col]\n",
        "        )\n",
        "    return data\n",
        "train = capping(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(63960, 33) (18655, 33)\n"
          ]
        }
      ],
      "source": [
        "# // Splitting the data into training and testing sets\n",
        "\n",
        "train_all = train.copy().dropna()\n",
        "train = train_all.loc[train_all.date < '2011-01-01']\n",
        "valid = train_all.loc[train_all.date > '2011-01-01']\n",
        "print(train.shape, valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hMjgH87RzOqX"
      },
      "outputs": [],
      "source": [
        "# Define input and output columns - you can play with adding or removing inputs to the model\n",
        "in_cols = ['climate_aet', 'climate_def', \n",
        "       'climate_pdsi', 'climate_pet', 'climate_pr', 'climate_ro',\n",
        "       'climate_soil', 'climate_srad', 'climate_swe', 'climate_tmmn',\n",
        "       'climate_tmmx', 'climate_vap', 'climate_vpd', 'climate_vs', 'elevation',\n",
        "       'landcover_0', 'landcover_1', 'landcover_2', 'landcover_3',\n",
        "       'landcover_4', 'landcover_5', 'landcover_6', 'landcover_7',\n",
        "       'landcover_8', 'precipitation'] # 'month', 'year', 'day', 'date'\n",
        "target_col = 'burn_area'\n",
        "\n",
        "\n",
        "X_train, y_train = train[in_cols], train[target_col]\n",
        "X_valid, y_valid = valid[in_cols], valid[target_col]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# // Feature selection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m visualizer \u001b[38;5;241m=\u001b[39m RFECV(\n\u001b[0;32m      4\u001b[0m     RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m     step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_root_mean_squared_log_error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m5.6\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m      9\u001b[0m visualizer\u001b[38;5;241m.\u001b[39mshow()\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yellowbrick\\model_selection\\rfecv.py:197\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_features_to_select \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_feature_subsets_:\n\u001b[0;32m    196\u001b[0m     rfe\u001b[38;5;241m.\u001b[39mset_params(n_features_to_select\u001b[38;5;241m=\u001b[39mn_features_to_select)\n\u001b[1;32m--> 197\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcv_params\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Convert scores to array\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_scores_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:264\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:311\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 311\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    314\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    315\u001b[0m     estimator,\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    317\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    318\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAHYCAYAAACfuyqzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgB0lEQVR4nO3dbWyV53348Z8fBHZhpjwEa6MKUUMJDgXH2FMnzdKkZWQQhfG0RJBMpAs0TFMgUrolAlRw2rKkJJrUlkkhmVxRFU0NgsLaUZRSmjdtEzQngExkZNIooaLrDq0RCBt7xuf/Ios310v+3PjEXPj+fCRenCvXfc5l/Wz65fic07JisVgMAAC4wcpv9AEAACBCmAIAkAhhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACThusO0r68v7rvvvnj99dc/dM9bb70V999/f9TX18fKlSujvb39eh8OAIAx7rrCtLe3N5544ono7Oz80D3d3d3x6KOPRlNTU+zfvz8aGhpi/fr10d3dfd2HBQBg7MocpmfOnIkHHngg3nvvvY/cd+jQoRg/fnw8+eSTcfvtt8eWLVtiwoQJcfjw4es+LAAAY1fmMD127Fh87nOfi+9+97sfue/EiRPR2NgYZWVlERFRVlYWCxYsiOPHj1/XQQEAGNsqs17w4IMPXtO+QqEQs2bNGrI2derUj/z1PwAA+fWxvSu/p6cnxo0bN2Rt3Lhx0dfXd833USwWS30sAAASlfkZ02s1fvz4YRHa19cXVVVV13wfZWVlcfFiT1y9OlDq45GYioryqKmpNu+cMO98Me98Me98mTSpOsrLS/c858cWprW1tXH+/Pkha+fPn4/p06dnup+rVweiv983dl6Yd76Yd76Yd76Ydz6U+pfbH9uv8uvr6+PNN98c/HV8sViMN954I+rr6z+uhwQA4CZW0jAtFApx5cqViIhYtGhRXLx4MbZv3x5nzpyJ7du3R09PTyxevLiUDwkAwBhR0jBtbm6OQ4cORUTExIkTY9euXdHW1hYrVqyIEydOxIsvvhif+MQnSvmQAACMEWXFxN/63tV12WtUcqCysjwmT55g3jlh3vli3vli3vkyZcqEqKgo3fOcH9trTAEAIAthCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkITMYdrb2xubN2+OpqamaG5ujtbW1g/d+6Mf/SgWL14cDQ0NsXr16jh16tSIDgsAwNiVOUx37NgR7e3tsXv37ti2bVvs3LkzDh8+PGxfZ2dnfPGLX4z169fHwYMHo66uLtavXx89PT0lOTgAAGNLpjDt7u6OvXv3xpYtW2Lu3LmxcOHCWLduXezZs2fY3p/+9Kcxa9asWLZsWdx6663xxBNPRKFQiDNnzpTs8AAAjB2VWTZ3dHREf39/NDQ0DK41NjbGCy+8EAMDA1Fe/j+d+8lPfjLOnDkTbW1t0dDQEPv374+JEyfGrbfemumAFRVeBpsHH8zZvPPBvPPFvPPFvPOlrKy095cpTAuFQkyePDnGjRs3uDZt2rTo7e2NCxcuxJQpUwbX77333jh69Gg8+OCDUVFREeXl5bFr166YNGlSpgPW1FRn2s/Nzbzzxbzzxbzzxby5HpnCtKenZ0iURsTg7b6+viHrXV1dUSgUYuvWrVFfXx//8i//Eps2bYrvfe97MXXq1Gt+zIsXe+Lq1YEsx+QmVFFRHjU11eadE+adL+adL+adL5MmVQ/5jflIZQrT8ePHDwvQD25XVVUNWX/++edj9uzZ8dBDD0VExFe+8pVYvHhx7Nu3Lx599NFrfsyrVweiv983dl6Yd76Yd76Yd76Ydz4Ui6W9v0yJW1tbG11dXdHf3z+4VigUoqqqKmpqaobsPXXqVMyZM+d/Hqi8PObMmRPnzp0b4ZEBABiLMoVpXV1dVFZWxvHjxwfX2traYt68ecOexp0+fXq8/fbbQ9beeeed+NSnPnX9pwUAYMzKFKbV1dWxbNmyaGlpiZMnT8aRI0eitbU11qxZExHvP3t65cqViIh44IEH4uWXX44DBw7Eu+++G88//3ycO3culi9fXvqvAgCAm16m15hGRGzatClaWlri4YcfjokTJ8aGDRvinnvuiYiI5ubmeOaZZ2LFihVx7733xuXLl2PXrl3xH//xH1FXVxe7d+/O9MYnAADyo6xYLPXLVkurq+uyF0/nQGVleUyePMG8c8K888W888W882XKlAkl/cxan34LAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQhMxh2tvbG5s3b46mpqZobm6O1tbWD917+vTpWL16dcyfPz+WLFkSr7322ogOCwDA2JU5THfs2BHt7e2xe/fu2LZtW+zcuTMOHz48bN+lS5fikUceiVmzZsX3v//9WLhwYTz22GPxm9/8piQHBwBgbMkUpt3d3bF3797YsmVLzJ07NxYuXBjr1q2LPXv2DNv7ve99Lz7xiU9ES0tLzJw5MzZu3BgzZ86M9vb2kh0eAICxozLL5o6Ojujv74+GhobBtcbGxnjhhRdiYGAgysv/p3OPHTsWd999d1RUVAyu7du3rwRHBgBgLMoUpoVCISZPnhzjxo0bXJs2bVr09vbGhQsXYsqUKYPrZ8+ejfnz58eXvvSlOHr0aMyYMSOeeuqpaGxszHTAigrvz8qDD+Zs3vlg3vli3vli3vlSVlba+8sUpj09PUOiNCIGb/f19Q1Z7+7ujhdffDHWrFkTL730Uvzbv/1brF27Nn74wx/G7//+71/zY9bUVGc5Ijc5884X884X884X8+Z6ZArT8ePHDwvQD25XVVUNWa+oqIi6urrYuHFjRETceeed8dOf/jQOHjwYf/M3f3PNj3nxYk9cvTqQ5ZjchCoqyqOmptq8c8K888W888W882XSpOohL+UcqUxhWltbG11dXdHf3x+Vle9fWigUoqqqKmpqaobsveWWW+LTn/70kLXbbrstfvWrX2U64NWrA9Hf7xs7L8w7X8w7X8w7X8w7H4rF0t5fpsStq6uLysrKOH78+OBaW1tbzJs3b1gt33XXXXH69Okha7/4xS9ixowZ139aAADGrExhWl1dHcuWLYuWlpY4efJkHDlyJFpbW2PNmjUR8f6zp1euXImIiFWrVsXp06fjm9/8Zrz77rvx9a9/Pc6ePRtLly4t/VcBAMBNL/OLAjZt2hRz586Nhx9+OJ5++unYsGFD3HPPPRER0dzcHIcOHYqIiBkzZsQ///M/x09+8pO477774ic/+Um8+OKLUVtbW9qvAACAMaGsWCz1qwNKq6vrsteo5EBlZXlMnjzBvHPCvPPFvPPFvPNlypQJJf1oMB8yBgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEjKHaW9vb2zevDmampqiubk5Wltb/7/X/PKXv4yGhoZ4/fXXr+uQAACMfZVZL9ixY0e0t7fH7t2749y5c/HUU0/FH/zBH8SiRYs+9JqWlpbo7u4e0UEBABjbMoVpd3d37N27N1566aWYO3duzJ07Nzo7O2PPnj0fGqb/+q//GpcvXy7JYQEAGLsy/Sq/o6Mj+vv7o6GhYXCtsbExTpw4EQMDA8P2d3V1xXPPPRdf/vKXR35SAADGtEzPmBYKhZg8eXKMGzducG3atGnR29sbFy5ciClTpgzZ/+yzz8by5cvjM5/5zHUfsKLC+7Py4IM5m3c+mHe+mHe+mHe+lJWV9v4yhWlPT8+QKI2Iwdt9fX1D1n/2s59FW1tb/OAHPxjRAWtqqkd0PTcX884X884X884X8+Z6ZArT8ePHDwvQD25XVVUNrl25ciW2bt0a27ZtG7J+PS5e7ImrV4e/TICxpaKiPGpqqs07J8w7X8w7X8w7XyZNqo7y8tI9O54pTGtra6Orqyv6+/ujsvL9SwuFQlRVVUVNTc3gvpMnT8bZs2dj48aNQ67/whe+EMuWLcv0mtOrVweiv983dl6Yd76Yd76Yd76Ydz4Ui6W9v0xhWldXF5WVlXH8+PFoamqKiIi2traYN2/ekFqeP39+vPLKK0Ouveeee+KrX/1q/PEf/3EJjg0AwFiTKUyrq6tj2bJl0dLSEv/wD/8Q//mf/xmtra3xzDPPRMT7z57+3u/9XlRVVcXMmTOHXV9bWxtTp04tzckBABhTMr8oYNOmTTF37tx4+OGH4+mnn44NGzbEPffcExERzc3NcejQoZIfEgCAsa+sWCz1qwNKq6vrsteo5EBlZXlMnjzBvHPCvPPFvPPFvPNlypQJJf1oMB8yBgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEoQpAABJEKYAACRBmAIAkARhCgBAEjKHaW9vb2zevDmampqiubk5WltbP3Tvq6++GkuXLo2GhoZYsmRJ/PjHPx7RYQEAGLsyh+mOHTuivb09du/eHdu2bYudO3fG4cOHh+3r6OiIxx57LFauXBkHDhyIVatWxeOPPx4dHR0lOTgAAGNLZZbN3d3dsXfv3njppZdi7ty5MXfu3Ojs7Iw9e/bEokWLhuz9wQ9+EH/0R38Ua9asiYiImTNnxtGjR+OHP/xhzJkzp3RfAQAAY0KmMO3o6Ij+/v5oaGgYXGtsbIwXXnghBgYGorz8f56AXb58efzXf/3XsPu4dOnSCI4LAMBYlSlMC4VCTJ48OcaNGze4Nm3atOjt7Y0LFy7ElClTBtdvv/32Idd2dnbGz3/+81i1alWmA1ZUeH9WHnwwZ/POB/POF/POF/POl7Ky0t5fpjDt6ekZEqURMXi7r6/vQ6/77W9/Gxs2bIgFCxbE3XffnemANTXVmfZzczPvfDHvfDHvfDFvrkemMB0/fvywAP3gdlVV1f95zfnz5+Ov//qvo1gsxje+8Y0hv+6/Fhcv9sTVqwOZruHmU1FRHjU11eadE+adL+adL+adL5MmVWduu4+SKUxra2ujq6sr+vv7o7Ly/UsLhUJUVVVFTU3NsP2//vWvB9/89O1vf3vIr/qv1dWrA9Hf7xs7L8w7X8w7X8w7X8w7H4rF0t5fpsStq6uLysrKOH78+OBaW1tbzJs3b1gtd3d3x7p166K8vDy+853vRG1tbUkODADA2JQpTKurq2PZsmXR0tISJ0+ejCNHjkRra+vgs6KFQiGuXLkSERG7du2K9957L772ta8N/rdCoeBd+QAA/J/KisVsT8L29PRES0tLvPLKKzFx4sRYu3ZtfP7zn4+IiDvuuCOeeeaZWLFiRSxatCjeeeedYdcvX748nn322Wt+vK6uy34VkAOVleUxefIE884J884X884X886XKVMmlPQTGDKH6WjzjZ0P/iLLF/POF/POF/POl1KHqQ8ZAwAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASIIwBQAgCcIUAIAkCFMAAJIgTAEASELmMO3t7Y3NmzdHU1NTNDc3R2tr64fufeutt+L++++P+vr6WLlyZbS3t4/osAAAjF2Zw3THjh3R3t4eu3fvjm3btsXOnTvj8OHDw/Z1d3fHo48+Gk1NTbF///5oaGiI9evXR3d3d0kODgDA2JIpTLu7u2Pv3r2xZcuWmDt3bixcuDDWrVsXe/bsGbb30KFDMX78+HjyySfj9ttvjy1btsSECRP+z4gFAIBMYdrR0RH9/f3R0NAwuNbY2BgnTpyIgYGBIXtPnDgRjY2NUVZWFhERZWVlsWDBgjh+/PjITw0AwJhTmWVzoVCIyZMnx7hx4wbXpk2bFr29vXHhwoWYMmXKkL2zZs0acv3UqVOjs7Mz0wEnTaqOYjHTJdyE/vvfL+adE+adL+adL+adL+XlZSW9v0xh2tPTMyRKI2Lwdl9f3zXt/d19/z/l5T44IE/MO1/MO1/MO1/Mm+uR6btm/Pjxw8Lyg9tVVVXXtPd39wEAQETGMK2trY2urq7o7+8fXCsUClFVVRU1NTXD9p4/f37I2vnz52P69OkjOC4AAGNVpjCtq6uLysrKIW9gamtri3nz5g17yr6+vj7efPPNKP73C0yKxWK88cYbUV9fP/JTAwAw5mQK0+rq6li2bFm0tLTEyZMn48iRI9Ha2hpr1qyJiPefPb1y5UpERCxatCguXrwY27dvjzNnzsT27dujp6cnFi9eXPqvAgCAm15ZsZjtPXM9PT3R0tISr7zySkycODHWrl0bn//85yMi4o477ohnnnkmVqxYERERJ0+ejG3btsXbb78dd9xxRzz99NNx5513lvyLAADg5pc5TAEA4OPgsxwAAEiCMAUAIAnCFACAJAhTAACScEPDtLe3NzZv3hxNTU3R3Nwcra2tH7r3rbfeivvvvz/q6+tj5cqV0d7ePoonpRSyzPvVV1+NpUuXRkNDQyxZsiR+/OMfj+JJKYUs8/7AL3/5y2hoaIjXX399FE5IKWWZ9+nTp2P16tUxf/78WLJkSbz22mujeFJKIcu8f/SjH8XixYujoaEhVq9eHadOnRrFk1JKfX19cd99933k39Ej7bUbGqY7duyI9vb22L17d2zbti127twZhw8fHravu7s7Hn300Whqaor9+/dHQ0NDrF+/Prq7u2/Aqble1zrvjo6OeOyxx2LlypVx4MCBWLVqVTz++OPR0dFxA07N9brWef9vLS0tfq5vUtc670uXLsUjjzwSs2bNiu9///uxcOHCeOyxx+I3v/nNDTg11+ta593Z2Rlf/OIXY/369XHw4MGoq6uL9evXR09Pzw04NSPR29sbTzzxRHR2dn7onpL0WvEGuXz5cnHevHnF1157bXDtn/7pn4p/9Vd/NWzv3r17i3/6p39aHBgYKBaLxeLAwEBx4cKFxX379o3aeRmZLPN+7rnnimvXrh2y9sgjjxT/8R//8WM/J6WRZd4fOHjwYHHVqlXF2bNnD7mO9GWZ9+7du4t/9md/Vuzv7x9cW7FiRfHVV18dlbMyclnm/a1vfau4fPnywduXLl0qzp49u3jy5MlROSul0dnZWfyLv/iL4pIlSz7y7+hS9NoNe8a0o6Mj+vv7o6GhYXCtsbExTpw4EQMDA0P2njhxIhobG6OsrCwiIsrKymLBggVD/q9RSVuWeS9fvjz+7u/+bth9XLp06WM/J6WRZd4REV1dXfHcc8/Fl7/85dE8JiWSZd7Hjh2Lu+++OyoqKgbX9u3bF3/yJ38yaudlZLLM+5Of/GScOXMm2traYmBgIPbv3x8TJ06MW2+9dbSPzQgcO3YsPve5z8V3v/vdj9xXil6rHMlBR6JQKMTkyZNj3Lhxg2vTpk2L3t7euHDhQkyZMmXI3lmzZg25furUqR/5dDJpyTLv22+/fci1nZ2d8fOf/zxWrVo1audlZLLMOyLi2WefjeXLl8dnPvOZ0T4qJZBl3mfPno358+fHl770pTh69GjMmDEjnnrqqWhsbLwRR+c6ZJn3vffeG0ePHo0HH3wwKioqory8PHbt2hWTJk26EUfnOj344IPXtK8UvXbDnjHt6ekZ8k0dEYO3+/r6rmnv7+4jXVnm/b/99re/jQ0bNsSCBQvi7rvv/ljPSOlkmffPfvazaGtri7/9278dtfNRWlnm3d3dHS+++GLccsst8dJLL8Uf/uEfxtq1a+NXv/rVqJ2Xkcky766urigUCrF169Z4+eWXY+nSpbFp0yavKR6jStFrNyxMx48fP+ygH9yuqqq6pr2/u490ZZn3B86fPx8PP/xwFIvF+MY3vhHl5T7d7GZxrfO+cuVKbN26NbZt2+bn+SaW5ee7oqIi6urqYuPGjXHnnXfG3//938dtt90WBw8eHLXzMjJZ5v3888/H7Nmz46GHHorPfvaz8ZWvfCWqq6tj3759o3ZeRk8peu2G/S99bW1tdHV1RX9//+BaoVCIqqqqqKmpGbb3/PnzQ9bOnz8f06dPH5WzMnJZ5h0R8etf/zoeeuih6Ovri29/+9vDfvVL2q513idPnoyzZ8/Gxo0bo6GhYfA1a1/4whdi69ato35urk+Wn+9bbrklPv3pTw9Zu+222zxjehPJMu9Tp07FnDlzBm+Xl5fHnDlz4ty5c6N2XkZPKXrthoVpXV1dVFZWDnlBbFtbW8ybN2/YM2P19fXx5ptvRrFYjIiIYrEYb7zxRtTX14/mkRmBLPPu7u6OdevWRXl5eXznO9+J2traUT4tI3Wt854/f3688sorceDAgcE/ERFf/epX4/HHHx/lU3O9svx833XXXXH69Okha7/4xS9ixowZo3FUSiDLvKdPnx5vv/32kLV33nknPvWpT43GURllpei1Gxam1dXVsWzZsmhpaYmTJ0/GkSNHorW1NdasWRMR7//r68qVKxERsWjRorh48WJs3749zpw5E9u3b4+enp5YvHjxjTo+GWWZ965du+K9996Lr33ta4P/rVAoeFf+TeRa511VVRUzZ84c8ifi/X91T5069UZ+CWSQ5ed71apVcfr06fjmN78Z7777bnz961+Ps2fPxtKlS2/kl0AGWeb9wAMPxMsvvxwHDhyId999N55//vk4d+5cLF++/EZ+CZRQyXttpJ9tNRLd3d3FJ598snjXXXcVm5ubi9/61rcG/9vs2bOHfO7ViRMnisuWLSvOmzev+Jd/+ZfFU6dO3YATMxLXOu8///M/L86ePXvYn6eeeuoGnZzrkeXn+3/zOaY3pyzz/vd///fi8uXLi5/97GeLS5cuLR47duwGnJiRyDLvl19+ubho0aLiXXfdVVy9enWxvb39BpyYUvndv6NL3WtlxeJ/P98KAAA3kLc5AwCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEkQpgAAJEGYAgCQBGEKAEAShCkAAEn4f21gIGR7wncQAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# // Feature selection\n",
        "\n",
        "visualizer = RFECV(\n",
        "    RandomForestRegressor(n_estimators=10, random_state=42, n_jobs=-1, criterion='squared_error'),\n",
        "    step=1, cv=3, scoring=\"neg_root_mean_squared_log_error\"\n",
        ")\n",
        "visualizer.fit(X_train, y_train)\n",
        "plt.figure(figsize=[5.6, 4])\n",
        "visualizer.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'RFE' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     X_test_rfe \u001b[38;5;241m=\u001b[39m sel\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train_rfe, X_test_rfe\n\u001b[1;32m---> 13\u001b[0m \u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mfeature_selection\u001b[1;34m(X_train, X_test, y_train, index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_selection\u001b[39m(X_train, X_test, y_train, index: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     sel \u001b[38;5;241m=\u001b[39m \u001b[43mRFE\u001b[49m(\n\u001b[0;32m      3\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mRandomForestRegressor(\n\u001b[0;32m      4\u001b[0m             n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m         ),\n\u001b[0;32m      6\u001b[0m         n_features_to_select\u001b[38;5;241m=\u001b[39mindex\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m     sel\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      9\u001b[0m     X_train_rfe \u001b[38;5;241m=\u001b[39m sel\u001b[38;5;241m.\u001b[39mtransform(X_train) \n",
            "\u001b[1;31mNameError\u001b[0m: name 'RFE' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "def feature_selection(X_train, X_test, y_train, index: int=train.shape[1]) -> tuple:\n",
        "    sel = RFE(\n",
        "        estimator=RandomForestRegressor(\n",
        "            n_estimators=100, random_state=42, n_jobs=-1\n",
        "        ),\n",
        "        n_features_to_select=index\n",
        "    )\n",
        "    sel.fit(X_train, y_train)\n",
        "    X_train_rfe = sel.transform(X_train) \n",
        "    X_test_rfe = sel.transform(X_test)\n",
        "    return X_train_rfe, X_test_rfe\n",
        "\n",
        "feature_selection(X_train, X_valid, y_train, index=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def scaler(X_train, X_test, minmax: bool=False):\n",
        "    stdscaler = StandardScaler()\n",
        "    X_train = stdscaler.fit_transform(X_train)\n",
        "    X_test = stdscaler.transform(X_test)\n",
        "\n",
        "    if minmax:\n",
        "        minmaxscaler = MinMaxScaler(feature_range=(0,1))\n",
        "        X_train = minmaxscaler.fit_transform(X_train)\n",
        "        X_test = minmaxscaler.transform(X_test)\n",
        "    return X_train, X_test\n",
        "\n",
        "X_train, X_valid = scaler(X_train=X_train, X_test=X_valid, minmax=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# // PCA\n",
        "\n",
        "\n",
        "pca = PCA(n_components=1, random_state=42)\n",
        "pca = pca.fit(X_train)\n",
        "X_train = pca.transform(X_train)\n",
        "X_valid = pca.transform(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-8j9zDpzUpc",
        "outputId": "dbd40957-1257-4126-9200-1105a10993ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.02855558927221779"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Create and fit the model\n",
        "model = RidgeCV()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_valid)\n",
        "mean_squared_error(y_valid, preds)**0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.03485312434643454"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Create and fit the model\n",
        "random_F = RandomForestRegressor(random_state=42)\n",
        "random_F.fit(X_train, y_train)\n",
        "preds = random_F.predict(X_valid)\n",
        "mean_squared_error(y_valid, preds)**0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.07291198056640737"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Create and fit the model\n",
        "svr = SVR(kernel='poly', gamma='auto', C=10)\n",
        "svr.fit(X_train, y_train)\n",
        "preds = svr.predict(X_valid)\n",
        "mean_squared_error(y_valid, preds)**0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.034265737794293684\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Data must be positive.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# // model with box-cox\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m boxcox, yeojohnson\n\u001b[1;32m---> 13\u001b[0m y_train_boxcox, lambda_boxcox \u001b[38;5;241m=\u001b[39m \u001b[43mboxcox\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m y_valid_boxcox \u001b[38;5;241m=\u001b[39m boxcox(y_valid, lmbda\u001b[38;5;241m=\u001b[39mlambda_boxcox)\n\u001b[0;32m     16\u001b[0m ada\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_boxcox)\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1118\u001b[0m, in \u001b[0;36mboxcox\u001b[1;34m(x, lmbda, alpha, optimizer)\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must not be constant.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(x \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be positive.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# If lmbda=None, find the lmbda that maximizes the log-likelihood function.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m lmax \u001b[38;5;241m=\u001b[39m boxcox_normmax(x, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n",
            "\u001b[1;31mValueError\u001b[0m: Data must be positive."
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "ada = AdaBoostRegressor(random_state=42, estimator=random_F, learning_rate=1e-4)\n",
        "ada.fit(X_train, y_train)\n",
        "preds = ada.predict(X_valid)\n",
        "print(mean_squared_error(y_valid, preds)**0.5 )\n",
        "\n",
        "\n",
        "\n",
        "# // model with box-cox\n",
        "\n",
        "y_train_boxcox, lambda_boxcox = boxcox(y_train)\n",
        "y_valid_boxcox = boxcox(y_valid, lmbda=lambda_boxcox)\n",
        "\n",
        "ada.fit(X_train, y_train_boxcox)\n",
        "preds = ada.predict(X_valid)\n",
        "print(mean_squared_error(y_valid_boxcox, preds)**0.5 )\n",
        "preds_original_scale = np.exp(np.log(preds) * lambda_boxcox + 1) / lambda_boxcox\n",
        "\n",
        "\n",
        "\n",
        "# // model with yeojohnson\n",
        "\n",
        "y_train_yeojohnson, lambda_boxcox = yeojohnson(y_train)\n",
        "y_valid_yeojohnson = boxcox(y_valid, lmbda=lambda_boxcox)\n",
        "\n",
        "ada.fit(X_train, y_train_yeojohnson)\n",
        "preds = ada.predict(X_valid)\n",
        "print(mean_squared_error(y_valid_yeojohnson, preds)**0.5) \n",
        "preds_original_scale = np.exp(np.log(preds) * lambda_boxcox + 1) / lambda_boxcox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# // model with yeojohnson\n",
        "\n",
        "y_train_yeojohnson, lambda_boxcox = yeojohnson(y_train)\n",
        "y_valid_yeojohnson = boxcox(y_valid, lmbda=lambda_boxcox)\n",
        "\n",
        "ada.fit(X_train, y_train_yeojohnson)\n",
        "preds = ada.predict(X_valid)\n",
        "print(mean_squared_error(y_valid_yeojohnson, preds)**0.5) \n",
        "preds_original_scale = np.exp(np.log(preds) * lambda_boxcox + 1) / lambda_boxcox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.026961837079682565"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "kn = KNeighborsRegressor(n_neighbors=3)\n",
        "kn.fit(X_train, y_train)\n",
        "preds = kn.predict(X_valid)\n",
        "mean_squared_error(y_valid, preds)**0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isI_-sfnzXED"
      },
      "outputs": [],
      "source": [
        "# // more models\n",
        "\n",
        "def grid_search(model, params):\n",
        "    grid = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    return grid.best_estimator_, grid.best_params_, np.sqrt(-grid.best_score_)\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": {\n",
        "        \"model\": LinearRegression(),\n",
        "        \"params\": {}\n",
        "    },\n",
        "    \"Ridge Regression\": {\n",
        "        \"model\": Ridge(random_state=42, alpha=1, solver='svd'),\n",
        "        \"params\": {\"alpha\": [0.1, 1, 10, 100]}\n",
        "    },\n",
        "    \"Random Forest Regression\": {\n",
        "        \"model\": RandomForestRegressor(random_state=42),\n",
        "        \"params\": {\"n_estimators\": [10, 50, 100], \"max_depth\": [None, 10, 20, 30]}\n",
        "    },\n",
        "    \"Gradient Boosting Regression\": {\n",
        "        \"model\": GradientBoostingRegressor(random_state=42),\n",
        "        \"params\": {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1], \"max_depth\": [3, 5, 7]}\n",
        "    },\n",
        "    \"K-Nearest Neighbors Regression\": {\n",
        "        \"model\": KNeighborsRegressor(),\n",
        "        \"params\": {\"n_neighbors\": [3, 5, 7], \"weights\": ['uniform', 'distance']}\n",
        "    },\n",
        "    \"LGBMRegressor\": {\n",
        "        \"model\": lgb.LGBMRegressor(),\n",
        "        \"params\": {\n",
        "                    'num_leaves': [31, 50, 70],\n",
        "                    'learning_rate': [0.01, 0.05, 0.1],\n",
        "                    'n_estimators': [100, 200, 500],\n",
        "                    'max_depth': [-1, 10, 20],\n",
        "                    'min_child_samples': [20, 50, 100],\n",
        "                    'subsample': [0.6, 0.8, 1.0],\n",
        "                    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "                }\n",
        "    },\n",
        "    \"\": {\n",
        "        \"model\": xgb.XGBRegressor(),\n",
        "        \"params\": {\n",
        "            'n_estimators': [100, 200, 500],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'max_depth': [3, 5, 7],\n",
        "            'min_child_weight': [1, 3, 5],\n",
        "            'subsample': [0.6, 0.8, 1.0],\n",
        "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "            'gamma': [0, 0.1, 0.2]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmK8kfNU7agI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression - Best Params: {}, RMSE: 0.02733069747339375\n",
            "Ridge Regression - Best Params: {'alpha': 100}, RMSE: 0.027330800334030417\n",
            "Random Forest Regression - Best Params: {'max_depth': 10, 'n_estimators': 100}, RMSE: 0.026179369068177295\n",
            "Gradient Boosting Regression - Best Params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}, RMSE: 0.025617402169930487\n",
            "K-Nearest Neighbors Regression - Best Params: {'n_neighbors': 7, 'weights': 'distance'}, RMSE: 0.025250276182806154\n",
            "\n",
            "Best Model: K-Nearest Neighbors Regression\n",
            "Test RMSE: 0.02514277990263765\n"
          ]
        }
      ],
      "source": [
        "# // Hyper-parameter tuning\n",
        "\n",
        "\n",
        "results = {}\n",
        "for name, config in models.items():\n",
        "    model, params, score = grid_search(config['model'], config['params'])\n",
        "    results[name] = {'Best Model': model, 'Best Params': params, 'RMSE': score}\n",
        "\n",
        "# Print the results\n",
        "for name, result in results.items():\n",
        "    print(f\"{name} - Best Params: {result['Best Params']}, RMSE: {result['RMSE']}\")\n",
        "\n",
        "\n",
        "best_model_name = min(results, key=lambda x: results[x]['RMSE'])\n",
        "best_model = results[best_model_name]['Best Model']\n",
        "test_rmse = np.sqrt(mean_squared_error(y_valid, best_model.predict(X_valid)))\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"Test RMSE: {test_rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# // Cross-validation\n",
        "\n",
        "\n",
        "X = train[in_cols]\n",
        "y = train['burn_area']\n",
        "cv = KFold(n_splits=10, shuffle=False)\n",
        "\n",
        "scores = []\n",
        "for train_index, test_index in cv.split(X=X, y=y):\n",
        "        X_train = X[train_index]\n",
        "        y_train = y[train_index]\n",
        "        X_test = X[test_index]\n",
        "        y_test = y[test_index]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "        print(mean_squared_error(y_test, preds)**0.5)\n",
        "        scores.append(mean_squared_error(y_test, preds)**0.5)\n",
        "\n",
        "print(\"The average score is {}\".format(np.mean(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "noise_factor = 0.1\n",
        "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
        "X_test_noisy = X_valid + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_valid.shape)\n",
        "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
        "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
        "\n",
        "\n",
        "input_data = Input(shape=(input_dim,))\n",
        "encoded = Dense(128, activation='relu')(input_data)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)  # Bottleneck\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
        "autoencoder = Model(input_data, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(X_train_noisy, X_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test_noisy, X_valid))\n",
        "\n",
        "\n",
        "encoder = Model(input_data, encoded)\n",
        "X_train_encoded = encoder.predict(X_train_noisy)\n",
        "X_valid_encoded = encoder.predict(X_test_noisy)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=512, activation='relu', input_shape=(X_train_encoded.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train_encoded, y_train, epochs=50, batch_size=256, validation_data=(X_valid_encoded, y_valid))\n",
        "\n",
        "\n",
        "preds = model.predict(X_valid_encoded)\n",
        "rmse = mean_squared_error(y_valid, preds)**0.5\n",
        "print(f'RMSE: {rmse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# // Hyper-parameter tuning - Keras-tuner\n",
        "\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units_1', min_value=128, max_value=512, step=32),\n",
        "        activation='relu', \n",
        "        input_shape=(X_train_encoded.shape[1],)\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units_3', min_value=16, max_value=64, step=16),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
        "        loss='mean_squared_error'\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='my_dir',\n",
        "    project_name='hyperparameter_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(X_train_encoded, y_train, epochs=50, validation_data=(X_valid_encoded, y_valid))\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_encoded, y_train, epochs=50, validation_data=(X_valid_encoded, y_valid))\n",
        "eval_result = model.evaluate(X_valid_encoded, y_valid)\n",
        "print(f\"Test RMSE: {eval_result**0.5}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq7DM0URkkai"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HItSe6MCkyPB",
        "outputId": "02b1ac1b-05bd-43c3-f3cf-13557c4a42f5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "test = test.drop(['ID'], axis=1)\n",
        "test['month'] = test.date.dt.month\n",
        "test['year'] = test.date.dt.year\n",
        "test['data'] = test.date.dt.dayofweek\n",
        "\n",
        "\n",
        "test = pca.transform(test[in_cols])\n",
        "preds = model.predict(test)#[in_cols].fillna(0))\n",
        "ss['burn_area'] = preds\n",
        "\n",
        "ss['burn_area'] = ss['burn_area'].clip(0, 1)\n",
        "ss.to_csv('starter_submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
