{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":825,"status":"ok","timestamp":1723807246902,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"2lLzfdilxfsY"},"outputs":[],"source":["import pandas as pd\n","from pmdarima import auto_arima\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from pykalman import KalmanFilter\n","from sklearn.cluster import KMeans\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2954,"status":"ok","timestamp":1723787465678,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"WAPM7kiAxVFG"},"outputs":[],"source":["train = pd.read_csv('../data/Train.csv')\n","test = pd.read_csv('../data/Test.csv')\n","sub = pd.read_csv('../data/SampleSubmission.csv')"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# \n","train['date'] = pd.to_datetime(train['ID'].apply(lambda x: x.split('_')[1]))\n","train['month'] = train.date.dt.month\n","train['year'] = train.date.dt.year\n","train['area'] = pd.to_numeric(train['ID'].apply(lambda x: x.split('_')[0]))\n","train.set_index('date', inplace=True)\n","\n","# Apply same procedure on test set\n","test['date'] = pd.to_datetime(test['ID'].apply(lambda x: x.split('_')[1]))\n","test['area'] = pd.to_numeric(test['ID'].apply(lambda x: x.split('_')[0]))\n","test.set_index('date', inplace=True)\n","\n","# Logically splitting data\n","X_train = train.loc[train.index.strftime('%Y-%m-%d') < '2013-01-01']\n","y_test = train.loc[train.index.strftime('%Y-%m-%d') >= '2013-01-01']"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1474858,"status":"ok","timestamp":1723792925287,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"z27wDVK9FKR_","outputId":"0733e2d2-6d73-451f-ecc2-738370031fa2"},"outputs":[],"source":["\n","preds = list()\n","\n","for area in train['area'].unique():\n","    train_area = train.loc[train.area == area]\n","    test_area = test.loc[test.area == area]\n","    try:\n","        sarima_fit = SARIMAX(\n","            train_area['burn_area'],\n","            order=(2, 0, 0),\n","            seasonal_order=(2, 0, 1, 12)\n","        ).fit()\n","        forecast_months = len(test_area)\n","        sarimax_pred = sarima_fit.get_forecast(steps=forecast_months, freq='MS')\n","        predicted_values = sarimax_pred.predicted_mean\n","\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_kf = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","        predicted_data_df = pd.DataFrame(\n","            {\n","                'ID': str(area)+'_'+test_area.index.strftime('%Y-%m-%d').map(str),\n","                'burn_area': predicted_data_kf.values\n","            }\n","        )\n","\n","    except Exception as e:\n","        model_arima= auto_arima(\n","            train_area['burn_area'], \n","            m=12,\n","            seasonal=True,\n","            start_p=0,\n","            start_q=0,\n","            max_order=5,\n","            test='adf',\n","            error_action= 'ignore',\n","            suppress_warnings=True,\n","            stepwise= True, trace= True\n","        )\n","\n","        forecast_months = len(test_area)\n","        predicted_values = model_arima.predict(n_periods=forecast_months)\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_kf = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","\n","        predicted_data_df = pd.DataFrame(\n","            {\n","                'ID': str(area) + '_' + test_area.index.strftime('%Y-%m-%d').map(str),\n","                'burn_area': predicted_data_kf.values\n","            }\n","        )\n","    preds.append(predicted_data_df)\n","    \n","\n","\n","df_combine = pd.DataFrame(columns=['ID', 'burn_area'])\n","for n in range(48):\n","    df = pd.DataFrame(columns=['ID', 'burn_area'])\n","    for i in range(len(preds)):\n","        df = pd.concat([df, preds[i].loc[preds[n].index == n]], ignore_index=True)\n","    df_combine = pd.concat([df_combine, df], ignore_index=True)\n","sub['burn_area'] = df_combine['burn_area']\n","sub['burn_area'] = sub['burn_area'].clip(0, 1)\n","sub.to_csv('../submissions/submit_1.csv', index=False)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Failed to tune real_id 102: All lag values up to 'maxlag' produced singular matrices. Consider using a longer series, a different lag term or a different test.. Falling back to default seasonal and non-seasonal order\n","Failed to tune real_id 368: All lag values up to 'maxlag' produced singular matrices. Consider using a longer series, a different lag term or a different test.. Falling back to default seasonal and non-seasonal order\n","Failed to tune real_id 377: Encountered exception in stationarity test ('adf'). This can occur in seasonal settings when a large enough `m` coupled with a large enough `D` difference the training array into too few samples for OLS (input contains 108 samples). Try fitting on a larger training size (raised from LinAlgError: Singular matrix). Falling back to default seasonal and non-seasonal order\n","Overall Test RMSE: 0.014202937143650576\n"]}],"source":["import numpy as np\n","from sklearn.metrics import mean_squared_error\n","rmse_values = []\n","predictions = []\n","\n","for real_id in train['area'].unique():\n","    train_area = train.loc[train.area == real_id]\n","    test_area = test.loc[test.area == real_id]\n","    X_train_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') < '2011-01-01']\n","    y_test_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","\n","    try:\n","        model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                  start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                  suppress_warnings=True, stepwise=True, trace=False)\n","        non_seasonal_order = model_arima.order\n","        best_seasonal_order = model_arima.seasonal_order\n","\n","    except Exception as e:\n","        non_seasonal_order = (2, 0, 0)\n","        best_seasonal_order = (2, 0, 1, 12)\n","\n","    try:\n","        sarimax_model = SARIMAX(X_train_area['burn_area'],\n","                                order=non_seasonal_order,\n","                                seasonal_order=best_seasonal_order)\n","        sarima_fit = sarimax_model.fit()\n","        forecast_months = len(y_test_area)\n","        sarimax_pred = sarima_fit.get_forecast(steps=forecast_months, freq='MS')\n","        predicted_values = sarimax_pred.predicted_mean\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=y_test_area.index, name='burn_area')\n","\n","    except Exception as e:\n","        try:\n","            model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                      start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                      suppress_warnings=True, stepwise=True, trace=False)\n","            forecast_length = len(y_test_area)\n","            predicted_values = model_arima.predict(n_periods=forecast_length)\n","            kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","            predicted_values_kf, _ = kf.filter(predicted_values.values)\n","            predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","\n","        except Exception as e:\n","            predicted_data_df = pd.Series(np.zeros(len(y_test_area)), index=y_test_area.index)\n","\n","    predicted_data_df = predicted_data_df.reindex(y_test_area.index, method='nearest')\n","    predicted_data_df = pd.DataFrame(\n","            {\n","                'ID': str(area) + '_' + test_area.index.strftime('%Y-%m-%d').map(str),\n","                'burn_area': predicted_data_kf.values\n","            }\n","        )\n","    predictions.append(predicted_data_df)\n","\n","    rmse_area = np.sqrt(mean_squared_error(y_test_area['burn_area'], predicted_data_df))\n","    rmse_values.append(rmse_area)\n","\n","if rmse_values:\n","    overall_rmse = np.mean(rmse_values)\n","    print('Overall Test RMSE:', overall_rmse)\n","else:\n","    print('No valid RMSE values were calculated')\n","    \n","    \n","df_combine = pd.DataFrame(columns=['ID', 'burn_area'])\n","for n in range(48):\n","    df = pd.DataFrame(columns=['ID', 'burn_area'])\n","    for i in range(len(predictions)):\n","        df = pd.concat([df, predictions[i].loc[predictions[n].index == n]], ignore_index=True)\n","    df_combine = pd.concat([df_combine, df], ignore_index=True)\n","sub['burn_area'] = df_combine['burn_area']\n","sub['burn_area'] = sub['burn_area'].clip(0, 1)\n","sub.to_csv('../submissions/submit_2.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["non_seasonal_order = (2, 0, 0)\n","best_seasonal_order = (2, 0, 1, 12)\n","rmse_values = []\n","predicted_values = []\n","\n","for real_id in train['real_id'].unique():\n","    train_area = train.loc[train.real_id == real_id]\n","    test_area = test.loc[test.real_id == real_id]\n","    X_train_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') < '2011-01-01']\n","    y_test_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","\n","    try:\n","        sarimax_model = SARIMAX(X_train_area['burn_area'],\n","                                order=non_seasonal_order,\n","                                seasonal_order=best_seasonal_order)\n","        sarima_fit = sarimax_model.fit()\n","        forecast_months = len(y_test_area)\n","        sarimax_pred = sarima_fit.get_forecast(steps=forecast_months, freq='MS')\n","        predicted_values = sarimax_pred.predicted_mean\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=y_test_area.index, name='burn_area')\n","\n","    except Exception as e:\n","        print(f\"Failed to model real_id {real_id}: {e}. Generating ARIMA forecast\")\n","        try:\n","            model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                      start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                      suppress_warnings=True, stepwise=True, trace=False)\n","            forecast_length = len(y_test_area)\n","            predicted_values = model_arima.predict(n_periods=forecast_length)\n","            kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","            predicted_values_kf, _ = kf.filter(predicted_values.values)\n","            predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","\n","        except Exception as e:\n","            predicted_data_df = pd.Series(np.zeros(len(y_test_area)), index=y_test_area.index)\n","\n","    predicted_data_df = predicted_data_df.reindex(y_test_area.index, method='nearest')\n","    predicted_data_df = pd.DataFrame(\n","            {\n","                'ID': str(area) + '_' + test_area.index.strftime('%Y-%m-%d').map(str),\n","                'burn_area': predicted_data_kf.values\n","            }\n","        )\n","    predictions.append(predicted_data_df)\n","    rmse_area = np.sqrt(mean_squared_error(y_test_area['burn_area'], predicted_data_df))\n","    rmse_values.append(rmse_area)\n","\n","if rmse_values:\n","    overall_rmse = np.mean(rmse_values)\n","    print('Overall Test RMSE:', overall_rmse)\n","else:\n","    print('No valid RMSE values were calculated')\n","    \n","\n","\n","df_combine = pd.DataFrame(columns=['ID', 'burn_area'])\n","for n in range(48):\n","    df = pd.DataFrame(columns=['ID', 'burn_area'])\n","    for i in range(len(predicted_values)):\n","        df = pd.concat([df, predicted_values[i].loc[predicted_values[n].index == n]], ignore_index=True)\n","    df_combine = pd.concat([df_combine, df], ignore_index=True)\n","sub['burn_area'] = df_combine['burn_area']\n","sub['burn_area'] = sub['burn_area'].clip(0, 1)\n","sub.to_csv('../submissions/submit_3.csv', index=False)"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
