{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":825,"status":"ok","timestamp":1723807246902,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"2lLzfdilxfsY"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import scipy.stats as stats\n","from sklearn.metrics import mean_squared_error\n","from matplotlib import pyplot as plt\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","from statsmodels.tsa.stattools import adfuller\n","\n","from pmdarima import auto_arima\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from pykalman import KalmanFilter\n","import joblib\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2954,"status":"ok","timestamp":1723787465678,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"WAPM7kiAxVFG"},"outputs":[],"source":["train = pd.read_csv('../data/Train.csv')\n","test = pd.read_csv('../data/Test.csv')\n","ss = pd.read_csv('../data/SampleSubmission.csv')"]},{"cell_type":"markdown","metadata":{"id":"Tnl3iVg5xqfA"},"source":["## 4.0 EDA + Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1445,"status":"ok","timestamp":1723793220504,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"eF2NXmXbSOaW","outputId":"af555993-35e8-4bcf-ea68-2bce169df4c8"},"outputs":[],"source":["# Look at correlation of all variables with the target (burn_area) variable\n","# Exclude the inappropriate columns from the original DataFrame\n","columns_to_exclude = ['ID', 'date', 'month', 'year']\n","numeric_columns = train.select_dtypes(include=['number']).drop(columns=columns_to_exclude, errors='ignore')\n","\n","# Calculate the correlation with 'burn_area'\n","correlation_with_burn_area = numeric_columns.corr()['burn_area']\n","\n","# Sort the correlation values\n","sorted_correlation_with_burn_area = correlation_with_burn_area.sort_values()\n","\n","# Print the sorted correlation values\n","print(sorted_correlation_with_burn_area)\n","\n","# Plot the correlations\n","train.select_dtypes(include=['number']).corr()['burn_area'].sort_values().plot(kind='bar', figsize=(18, 6))"]},{"cell_type":"markdown","metadata":{"id":"xXIk62X9iONj"},"source":["### 4.1 Adding date features"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":547,"status":"ok","timestamp":1723787481690,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"pn-SKQxiHAon"},"outputs":[],"source":["# Split the ID (eg 127_2017-01-03) to get the date string, which we convert to datetime to make life easier\n","train['date'] = pd.to_datetime(train['ID'].apply(lambda x: x.split('_')[1]))\n","test['date'] = pd.to_datetime(test['ID'].apply(lambda x: x.split('_')[1]))"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":559,"status":"ok","timestamp":1723787485055,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"bag8HJpxCucw"},"outputs":[],"source":["# Add month and year date variables\n","train['month'] = train.date.dt.month\n","train['year'] = train.date.dt.year"]},{"cell_type":"markdown","metadata":{"id":"E0njDz3u5u7n"},"source":["### 4.2 Adding Real ID column"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":424,"status":"ok","timestamp":1723787498133,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"BD2eblw75t60"},"outputs":[],"source":["# Split the ID (eg 127_2017-01-03) to get the area ID\n","train['real_id'] = pd.to_numeric(train['ID'].apply(lambda x: x.split('_')[0]))\n","test['real_id'] = pd.to_numeric(test['ID'].apply(lambda x: x.split('_')[0]))"]},{"cell_type":"markdown","metadata":{"id":"zkRzrcszRPte"},"source":["### 4.3 Trend and Seasonality Analysis\n","We have visually observed the easonality of the burned area.\n","The country is divided into 533 areas and each area has its own historical data.\n","We will therefore, convert the data to a time series and split burn_area data into seasonal, underlying trend, and residual components for sample areas."]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":476,"status":"ok","timestamp":1723787502046,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"OuubmduHuml1"},"outputs":[],"source":["# Set date column as the index\n","train.set_index('date', inplace=True)\n","test.set_index('date', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":631},"executionInfo":{"elapsed":2881,"status":"ok","timestamp":1723791188622,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"7rSmmbh-8WBH","outputId":"55e682d2-a8ae-415e-d80f-e41f4bb7ae59"},"outputs":[],"source":["# Time series decomposition of area ID 0\n","train_0 = train.loc[train.real_id == 0]\n","\n","decomposition_result = seasonal_decompose(train_0['burn_area'], model='additive', period=12)  # Annual seasonality\n","\n","# Plot the original time series\n","plt.figure(figsize=(15, 8))\n","plt.subplot(4, 1, 1)\n","plt.plot(train['burn_area'], label='Original')\n","plt.legend(loc='upper left')\n","\n","# Plot the trend\n","plt.subplot(4, 1, 2)\n","plt.plot(decomposition_result.trend, label='Trend')\n","plt.legend(loc='upper left')\n","\n","# Plot the seasonal component\n","plt.subplot(4, 1, 3)\n","plt.plot(decomposition_result.seasonal, label='Seasonal')\n","plt.legend(loc='upper left')\n","\n","# Plot the residual or noise\n","plt.subplot(4, 1, 4)\n","plt.plot(decomposition_result.resid, label='Residual')\n","plt.legend(loc='upper left')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":1373,"status":"ok","timestamp":1723791107055,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"uw3uh9HE9Kpp","outputId":"ad6d4b01-b7f8-4016-9ca2-ff4a50ca1a74"},"outputs":[],"source":["# Plot a Q-Q plot of the residuals to see if they are normally distributed\n","stats.probplot(decomposition_result.resid, dist=\"norm\", plot=plt)\n","plt.title('Q-Q Plot of Residuals')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3418,"status":"ok","timestamp":1723791273013,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"sI4srfI29mYM","outputId":"6fbf0fa7-71b8-4b01-ed00-c838c6a9b9b2"},"outputs":[],"source":["# Time series decomposition of area ID 78\n","train_78 = train.loc[train.real_id == 78]\n","\n","decomposition_result = seasonal_decompose(train_78['burn_area'], model='additive', period=12)  # Annual seasonality\n","\n","# Plot the original time series\n","plt.figure(figsize=(15, 8))\n","plt.subplot(4, 1, 1)\n","plt.plot(train['burn_area'], label='Original')\n","plt.legend(loc='upper left')\n","\n","# Plot the trend\n","plt.subplot(4, 1, 2)\n","plt.plot(decomposition_result.trend, label='Trend')\n","plt.legend(loc='upper left')\n","\n","# Plot the seasonal component\n","plt.subplot(4, 1, 3)\n","plt.plot(decomposition_result.seasonal, label='Seasonal')\n","plt.legend(loc='upper left')\n","\n","# Plot the residual or noise\n","plt.subplot(4, 1, 4)\n","plt.plot(decomposition_result.resid, label='Residual')\n","plt.legend(loc='upper left')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot a Q-Q plot of the residuals to see if they are normally distributed\n","stats.probplot(decomposition_result.resid, dist=\"norm\", plot=plt)\n","plt.title('Q-Q Plot of Residuals')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":706,"status":"ok","timestamp":1723791136510,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"sF3nGyWp9SUy","outputId":"abcfb30b-5f05-4d62-c5be-8b7aff99cf28"},"outputs":[],"source":["# Drop NaN values from residuals\n","clean_residuals = decomposition_result.resid.dropna()\n","\n","# Run the ADF test on the cleaned residuals\n","adf_test = adfuller(clean_residuals)\n","print(f\"ADF Statistic: {adf_test[0]}\")\n","print(f\"p-value: {adf_test[1]}\")\n","\n","if adf_test[1] < 0.05:\n","    print(\"The residuals are stationary.\")\n","else:\n","    print(\"The residuals are not stationary.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":486,"status":"ok","timestamp":1723787511167,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"OGmRwBVy1nsf","outputId":"f3eaf5f9-b8ba-4291-942b-e2a0ac06ca0f"},"outputs":[],"source":["# Convert date to string and split at 2011-01-01\n","X_train = train.loc[train.index.strftime('%Y-%m-%d') < '2011-01-01']\n","y_test = train.loc[train.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","print(X_train.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1881472,"status":"ok","timestamp":1723725350052,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"WlDkmkJ96SHL","outputId":"cf99879c-e3ba-45d3-b6fd-63f8953c4e93"},"outputs":[],"source":["# Initialize an empty list to store RMSE values for each area\n","rmse_values = []\n","\n","# Loop through each area ID\n","for real_id in train['real_id'].unique():\n","    # Filter the train and test data for the current area ID\n","    train_area = train.loc[train.real_id == real_id]\n","    test_area = test.loc[test.real_id == real_id]\n","\n","    # Train Test Split\n","    X_train_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') < '2011-01-01']\n","    y_test_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","\n","    # Simple model\n","    baseline_model = auto_arima(X_train_area['burn_area'], seasonal=True)\n","\n","    # Forecast the same length as the test data\n","    forecast_length = len(y_test_area)\n","    predicted_data = baseline_model.predict(n_periods=forecast_length)\n","    predicted_data = pd.Series(predicted_data, index=y_test_area.index)\n","\n","    # Calculate RMSE for the current area ID\n","    rmse_area = np.sqrt(mean_squared_error(y_test_area['burn_area'], predicted_data))\n","    rmse_values.append(rmse_area)\n","\n","# Calculate the overall RMSE by averaging the RMSE values of all areas\n","overall_rmse = np.mean(rmse_values)\n","print('Overall Test RMSE:', overall_rmse)"]},{"cell_type":"markdown","metadata":{"id":"8nN-ulz8by26"},"source":["#### 5.2.2 Tuned Auto ARIMA model"]},{"cell_type":"markdown","metadata":{"id":"-1AB7LtJ8A3d"},"source":["The auto ARIMA model can be tuned to test different combinations of seasonal (P, D, Q) and non-seasonal orders p, d, and q (where p, d, and q represent the autoregressive, differencing, and moving average terms, respectively) and generate the best order combination.\n","\n","To limit the computation complexity and time, we will set max_order=5, which means that the sum of P, Q, and D or p, q, and d cannot exceed 5.\n","Augmented Dickey-Fuller test \"adf\" will be used to determine the optimal differencing term.\n"]},{"cell_type":"markdown","metadata":{"id":"OlM25rEDCwGB"},"source":["NB: From my tests, I realised that some areas such as 270 and 271 have insufficient variability of burned area data, making it impossible for the model to test and determine an appropriate differencing term, d."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":472,"status":"ok","timestamp":1723750456159,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"_K-AwqifCthc","outputId":"e55e2b95-2c6d-4744-9028-c6eacdd9924f"},"outputs":[],"source":["# Time Series for area 270\n","train_270 = train.loc[train.real_id == 270]\n","\n","# Time Series for area 271\n","train_271 = train.loc[train.real_id == 271]\n","\n","# burned area value counts for area 270\n","train_270['burn_area'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1723750460307,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"sl_xSSiQFGaX","outputId":"142bed02-ddf7-428e-f6f2-2f8b0bbcbac1"},"outputs":[],"source":["# burned area value counts for area 271\n","train_271['burn_area'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"CvqX3q8vFQje"},"source":["Almost all the area that failed the auto ARIMA model test have only one non-zero value and 155 zeros.\n","\n","Therefore, in my modelling, I will introduce try and except blocks so that areas whose data cannot be modelled will be imputed with 0 as the prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12380568,"status":"ok","timestamp":1723746008435,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"QPKOK9JA-83A","outputId":"3d6efe75-10a2-4ef4-b8e1-163143c2532a"},"outputs":[],"source":["# Looping through all areas and solving for areas with insufficient data or\n","# insufficient variability\n","\n","# Initialize an empty list to store RMSE values for each area\n","rmse_values = []\n","\n","# Loop through each area ID\n","for real_id in train['real_id'].unique():\n","    # Filter the train and test data for the current area ID\n","    train_area = train.loc[train.real_id == real_id]\n","    test_area = test.loc[test.real_id == real_id]\n","\n","    # Train Test Split\n","    X_train_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') < '2011-01-01']\n","    y_test_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","\n","    # Skip if the time series is too short or non-variable\n","    if len(X_train_area) < 20 or X_train_area['burn_area'].std() == 0:\n","        print(f\"Skipping real_id {real_id} due to insufficient data or no variability. Falling back to zero prediction.\")\n","        # Fall back to simple zero prediction\n","        predicted_data = np.zeros(len(y_test_area))\n","    else:\n","        try:\n","            # Auto ARIMA model tuning\n","            model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                     start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                     suppress_warnings=True, stepwise=True, trace=False)\n","            forecast_length = len(y_test_area)\n","            predicted_data = model_arima.predict(n_periods=forecast_length)\n","            predicted_data = pd.Series(predicted_data, index=y_test_area.index)\n","        except Exception as e:\n","            print(f\"Failed to model real_id {real_id}: {e}. Falling back to zero prediction.\")\n","            # Fall back to simple zero prediction\n","            predicted_data = np.zeros(len(y_test_area))\n","\n","        # Calculate RMSE for the current area ID\n","        rmse_area = np.sqrt(mean_squared_error(y_test_area['burn_area'], predicted_data))\n","        rmse_values.append(rmse_area)\n","\n","# Calculate the overall RMSE by averaging the RMSE values of all areas\n","if rmse_values:\n","    overall_rmse = np.mean(rmse_values)\n","    print('Overall Test RMSE:', overall_rmse)\n","else:\n","    print('No valid RMSE values were calculated')"]},{"cell_type":"markdown","metadata":{"id":"qCd0QEcYoevn"},"source":["### 5.3 SARIMAX Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1631794,"status":"ok","timestamp":1723752287939,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"brGbFcC92KSH","outputId":"3b8e2fbd-a665-4571-a803-38cce517ae51"},"outputs":[],"source":["# SARIMAX with exogenous variables and train-test split\n","# Set best order as one set of values obtained via auto ARIMA\n","non_seasonal_order = (2, 0, 0)\n","best_seasonal_order = (2, 0, 1, 12)\n","\n","# Initialize an empty list to RMSE values for each area\n","rmse_values = []\n","\n","# Loop through each area ID\n","for real_id in train['real_id'].unique():\n","    # Filter the train and test data for the current area ID\n","    train_area = train.loc[train.real_id == real_id]\n","    test_area = test.loc[test.real_id == real_id]\n","\n","    # Lagged landcover_5 feature\n","    train_area['landcover_5_lag1'] = train_area['landcover_5'].shift(1)\n","    test_area['landcover_5_lag1'] = test_area['landcover_5'].shift(1)\n","\n","    # Intercation terms\n","    train_area['climate_def_climate_vs'] = train_area['climate_def'] * train_area['climate_vs']\n","    test_area['climate_def_climate_vs'] = test_area['climate_def'] * test_area['climate_vs']\n","\n","    train_area['climate_pet_climate_vpd'] = train_area['climate_pet'] * train_area['climate_vpd']\n","    test_area['climate_pet_climate_vpd'] = test_area['climate_pet'] * test_area['climate_vpd']\n","\n","    # Select top correlated features, lagged and interaction features as exogenous variables\n","    exog_features = ['climate_def', 'climate_vs', 'climate_vpd', 'climate_srad', 'climate_pet',\n","                     'elevation', 'landcover_5', 'landcover_5_lag1', 'climate_def_climate_vs',\n","                     'climate_pet_climate_vpd']\n","\n","    # Train Test Split\n","    X_train_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') < '2011-01-01']\n","    y_test_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","\n","    # Prepare exogenous variables for the training and test sets\n","    X_train_exog = X_train_area[exog_features]\n","    y_test_exog = y_test_area[exog_features]\n","\n","    # Backward fill NaNs in exog variables\n","    X_train_exog.fillna(method='bfill', inplace=True)\n","    y_test_exog.fillna(method='bfill', inplace=True)\n","\n","    try:\n","        # Fit SARIMA model with the best orders on train set\n","        sarimax_model = SARIMAX(X_train_area['burn_area'],\n","                                order=non_seasonal_order,\n","                                seasonal_order=best_seasonal_order,\n","                                exog=X_train_exog)\n","        sarima_fit = sarimax_model.fit()\n","\n","        # Forecast for the specific number of months\n","        forecast_months = len(y_test_area)\n","\n","        # Perform the forecast\n","        sarimax_pred = sarima_fit.get_forecast(steps=forecast_months, exog=y_test_exog, freq='MS')\n","\n","        # Extract predicted values\n","        predicted_values = sarimax_pred.predicted_mean\n","\n","        # Interpolate NaN values in the predictions\n","        predicted_values = predicted_values.interpolate(method='linear')\n","\n","    except Exception as e:\n","        print(f\"Failed to model real_id {real_id}: {e}. Generating ARIMA forecast\")\n","        try:\n","            # Auto ARIMA model tuning\n","            model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                      start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                      suppress_warnings=True, stepwise=True, trace=False)\n","            forecast_length = len(y_test_area)\n","            predicted_values = model_arima.predict(n_periods=forecast_length)\n","            predicted_values = pd.Series(predicted_values, index=y_test_area.index)\n","\n","            # Interpolate NaN values in the predictions\n","            predicted_values = predicted_values.interpolate(method='linear')\n","\n","        except Exception as e:\n","            print(f\"Failed to model real_id {real_id}: {e}. Falling back to zero prediction.\")\n","            # Fall back to simple zero prediction\n","            predicted_values = pd.Series(np.zeros(len(y_test_area)), index=y_test_area.index)\n","\n","    # Ensure alignment\n","    predicted_values = predicted_values.reindex(y_test_area.index, method='nearest')\n","\n","    # Calculate RMSE for the current area ID\n","    rmse_area = np.sqrt(mean_squared_error(y_test_area['burn_area'], predicted_values))\n","    rmse_values.append(rmse_area)\n","\n","# Calculate the overall RMSE by averaging the RMSE values of all areas\n","if rmse_values:\n","    overall_rmse = np.mean(rmse_values)\n","    print('Overall Test RMSE:', overall_rmse)\n","else:\n","    print('No valid RMSE values were calculated')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":982706,"status":"ok","timestamp":1723753660761,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"2LaPxY9HDB5t","outputId":"a836768b-92e3-421f-b0dc-2a5837fc33d3"},"outputs":[],"source":["# Univariate SARIMAX with train-test split, Kalman Filter applied to the predictions\n","# and Auto ARIMA for areas where SARIMAX returns an error\n","\n","# Set best order as the values obtained via auto ARIMA tuning\n","non_seasonal_order = (2, 0, 0)\n","best_seasonal_order = (2, 0, 1, 12)\n","\n","# Initialize an empty list to RMSE values for each area\n","rmse_values = []\n","\n","# Loop through each area ID\n","for real_id in train['real_id'].unique():\n","    # Filter the train and test data for the current area ID\n","    train_area = train.loc[train.real_id == real_id]\n","    test_area = test.loc[test.real_id == real_id]\n","\n","    # Train Test Split\n","    X_train_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') < '2011-01-01']\n","    y_test_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","\n","    try:\n","        # Fit SARIMA model with the best orders on X_train set\n","        sarimax_model = SARIMAX(X_train_area['burn_area'],\n","                                order=non_seasonal_order,\n","                                seasonal_order=best_seasonal_order)\n","        sarima_fit = sarimax_model.fit()\n","\n","        # Forecast for the specific number of months\n","        forecast_months = len(y_test_area)\n","\n","        # Perform the forecast\n","        sarimax_pred = sarima_fit.get_forecast(steps=forecast_months, freq='MS')\n","\n","        # Extract predicted values\n","        predicted_values = sarimax_pred.predicted_mean\n","\n","        # Apply Kalman Filter to smooth the predictions\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=y_test_area.index, name='burn_area')\n","\n","    except Exception as e:\n","        print(f\"Failed to model real_id {real_id}: {e}. Generating ARIMA forecast\")\n","        try:\n","            # Auto ARIMA model tuning\n","            model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                      start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                      suppress_warnings=True, stepwise=True, trace=False)\n","            forecast_length = len(y_test_area)\n","            predicted_values = model_arima.predict(n_periods=forecast_length)\n","            # Apply Kalman Filter to smooth the predictions\n","            kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","            predicted_values_kf, _ = kf.filter(predicted_values.values)\n","            predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","\n","        except Exception as e:\n","            print(f\"Failed to model real_id {real_id}: {e}. Falling back to zero prediction.\")\n","            # Fall back to simple zero prediction\n","            predicted_data_df = pd.Series(np.zeros(len(y_test_area)), index=y_test_area.index)\n","\n","    # Ensure alignment\n","    predicted_data_df = predicted_data_df.reindex(y_test_area.index, method='nearest')\n","\n","    # Calculate RMSE for the current area ID\n","    rmse_area = np.sqrt(mean_squared_error(y_test_area['burn_area'], predicted_data_df))\n","    rmse_values.append(rmse_area)\n","\n","# Calculate the overall RMSE by averaging the RMSE values of all areas\n","if rmse_values:\n","    overall_rmse = np.mean(rmse_values)\n","    print('Overall Test RMSE:', overall_rmse)\n","else:\n","    print('No valid RMSE values were calculated')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11071370,"status":"ok","timestamp":1723804663603,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"QQavrJHYwsQi","outputId":"2cc15cea-6ffb-42d6-cd63-453fe28b41fa"},"outputs":[],"source":["# Univariate SARIMAX with train-test split and Kalman Filter applied to the predictions\n","# and Auto ARIMA for areas where SARIMAX returns an error\n","\n","# Initialize an empty list to RMSE values for each area\n","rmse_values = []\n","\n","# Loop through each area ID\n","for real_id in train['real_id'].unique():\n","    # Filter the train and test data for the current area ID\n","    train_area = train.loc[train.real_id == real_id]\n","    test_area = test.loc[test.real_id == real_id]\n","\n","    # Train Test Split\n","    X_train_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') < '2011-01-01']\n","    y_test_area = train_area.loc[train_area.index.strftime('%Y-%m-%d') >= '2011-01-01']\n","\n","    try:\n","        # Auto ARIMA model tuning\n","        model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                  start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                  suppress_warnings=True, stepwise=True, trace=False)\n","        # Set best order as the values obtained via auto ARIMA\n","        non_seasonal_order = model_arima.order\n","        best_seasonal_order = model_arima.seasonal_order\n","\n","    except Exception as e:\n","        print(f\"Failed to tune real_id {real_id}: {e}. Falling back to default seasonal and non-seasonal order\")\n","        # Default best order terms\n","        non_seasonal_order = (2, 0, 0)\n","        best_seasonal_order = (2, 0, 1, 12)\n","\n","    try:\n","        # Fit SARIMA model with the best orders on train set\n","        sarimax_model = SARIMAX(X_train_area['burn_area'],\n","                                order=non_seasonal_order,\n","                                seasonal_order=best_seasonal_order)\n","        sarima_fit = sarimax_model.fit()\n","\n","        # Forecast for the specific number of months\n","        forecast_months = len(y_test_area)\n","\n","        # Perform the forecast\n","        sarimax_pred = sarima_fit.get_forecast(steps=forecast_months, freq='MS')\n","\n","        # Extract predicted values\n","        predicted_values = sarimax_pred.predicted_mean\n","\n","        # Apply Kalman Filter to smooth the predictions\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=y_test_area.index, name='burn_area')\n","\n","    except Exception as e:\n","        print(f\"Failed to model real_id {real_id}: {e}. Generating ARIMA forecast\")\n","        try:\n","            # Auto ARIMA model tuning\n","            model_arima = auto_arima(X_train_area['burn_area'], m=12, seasonal=True,\n","                                      start_p=0, start_q=0, max_order=5, test='adf', error_action='ignore',\n","                                      suppress_warnings=True, stepwise=True, trace=False)\n","            forecast_length = len(y_test_area)\n","            predicted_values = model_arima.predict(n_periods=forecast_length)\n","            # Apply Kalman Filter to smooth the predictions\n","            kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","            predicted_values_kf, _ = kf.filter(predicted_values.values)\n","            predicted_data_df = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","\n","        except Exception as e:\n","            print(f\"Failed to model real_id {real_id}: {e}. Falling back to zero prediction.\")\n","            # Fall back to simple zero prediction\n","            predicted_data_df = pd.Series(np.zeros(len(y_test_area)), index=y_test_area.index)\n","\n","    # Ensure alignment\n","    predicted_data_df = predicted_data_df.reindex(y_test_area.index, method='nearest')\n","\n","    # Calculate RMSE for the current area ID\n","    rmse_area = np.sqrt(mean_squared_error(y_test_area['burn_area'], predicted_data_df))\n","    rmse_values.append(rmse_area)\n","\n","# Calculate the overall RMSE by averaging the RMSE values of all areas\n","if rmse_values:\n","    overall_rmse = np.mean(rmse_values)\n","    print('Overall Test RMSE:', overall_rmse)\n","else:\n","    print('No valid RMSE values were calculated')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1474858,"status":"ok","timestamp":1723792925287,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"z27wDVK9FKR_","outputId":"0733e2d2-6d73-451f-ecc2-738370031fa2"},"outputs":[],"source":["# Univariate SARIMAX trained on full data with Kalman Filter applied to the predictions\n","# and Auto ARIMA for areas where SARIMAX returns an error\n","\n","# Set best order as the values obtained via auto ARIMA\n","non_seasonal_order = (2, 0, 0)\n","best_seasonal_order = (2, 0, 1, 12)\n","\n","# Initialize an empty list to store predicted values for each area\n","predicted_data_list = []\n","\n","# Loop through each area ID\n","for real_id in train['real_id'].unique():\n","    # Filter the train and test data for the current area ID\n","    train_area = train.loc[train.real_id == real_id]\n","    test_area = test.loc[test.real_id == real_id]\n","\n","    try:\n","        # Fit SARIMA model with the best orders on train set\n","        sarimax_model = SARIMAX(train_area['burn_area'],\n","                                order=non_seasonal_order,\n","                                seasonal_order=best_seasonal_order)\n","        sarima_fit = sarimax_model.fit()\n","\n","        # Forecast for the specific number of months\n","        forecast_months = len(test_area)\n","\n","        # Perform the forecast\n","        sarimax_pred = sarima_fit.get_forecast(steps=forecast_months, freq='MS')\n","\n","        # Extract predicted values\n","        predicted_values = sarimax_pred.predicted_mean\n","\n","        # Apply Kalman Filter to smooth the predictions\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_kf = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","\n","        # Add the real_id back to the predicted_data\n","        predicted_data_df = pd.DataFrame({'ID': str(real_id) + '_' + test_area.index.strftime('%Y-%m-%d').map(str),\n","                                          'burn_area': predicted_data_kf.values})\n","\n","    except Exception as e:\n","        print(f\"Failed to model real_id {real_id}: {e}. Generating an ARIMA forecast\")\n","        # Auto ARIMA model with a few adjusted parameters\n","        model_arima= auto_arima(train_area['burn_area'], m=12, seasonal=True,\n","                            start_p=0, start_q=0, max_order=5, test='adf', error_action= 'ignore',\n","                            suppress_warnings=True,\n","                            stepwise= True, trace= True)\n","\n","        # Forecast the same length as the test data\n","        forecast_months = len(test_area)\n","        predicted_values = model_arima.predict(n_periods=forecast_months)\n","\n","        # Apply Kalman Filter to smooth the predictions\n","        kf = KalmanFilter(initial_state_mean=predicted_values.iloc[0], n_dim_obs=1)\n","        predicted_values_kf, _ = kf.filter(predicted_values.values)\n","        predicted_data_kf = pd.Series(predicted_values_kf.flatten(), index=test_area.index, name='burn_area')\n","\n","        # Add the real_id back to the predicted_data\n","        predicted_data_df = pd.DataFrame({'ID': str(real_id) + '_' + test_area.index.strftime('%Y-%m-%d').map(str),\n","                                          'burn_area': predicted_data_kf.values})\n","\n","    # Add predicted data to predicted_data_list\n","    predicted_data_list.append(predicted_data_df)"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":1181,"status":"ok","timestamp":1723805450931,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"hcqAcC8Gdv22"},"outputs":[],"source":["# Write a pickle file for the predictions\n","with open('SARIMAX_predicted_data_list.pkl', 'wb') as f:\n","    joblib.dump(predicted_data_list, f)"]},{"cell_type":"markdown","metadata":{"id":"Eq7DM0URkkai"},"source":["## 6.0 Making A Submission\n","\n","Once we've got some features and a model we're happy with, it's time to submit!"]},{"cell_type":"markdown","metadata":{"id":"u0DUZkL4hWtn"},"source":["Here we will concatenate the generated list of predictions into one dataframe in such a manner that, predictions for all areas in a certain month will be grouped together chronologically. This will result in a dataframe whose 'ID' column values match the 'ID' column of the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14961,"status":"ok","timestamp":1723805497548,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"qqKayApZAbrV","outputId":"cab0ab14-3e25-42df-9387-e020fc5b8f8f"},"outputs":[],"source":["# Initialize an empty dataframe\n","df_combine = pd.DataFrame(columns=['ID', 'burn_area'])\n","\n","# Loop through the number of predicted months (48 months)\n","for n in range(48):\n","    df = pd.DataFrame(columns=['ID', 'burn_area'])\n","\n","    # Loop through each area ID\n","    for i in range(len(predicted_data_list)):\n","        df = pd.concat([df, predicted_data_list[i].loc[predicted_data_list[n].index == n]], ignore_index=True)\n","    df_combine = pd.concat([df_combine, df], ignore_index=True)\n","\n","# View the first 5 rows\n","df_combine.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1723805509476,"user":{"displayName":"Leonard Mwangi","userId":"02363524813695713194"},"user_tz":-180},"id":"2tqCY70iLfnf","outputId":"404f9a87-0673-4cd9-dc28-43f34979ff35"},"outputs":[],"source":["# Add to submission dataframe and clip the values\n","ss['burn_area'] = df_combine['burn_area']\n","\n","# Depending on your model, you may have some predictions that don't make sense. Let's constrain our predictions to the range (0, 1)\n","ss['burn_area'] = ss['burn_area'].clip(0, 1)\n","\n","# View\n","ss.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13Ns-f5blIEs"},"outputs":[],"source":["# Save ready for submission:\n","ss.to_csv('SARIMAX_fulldata_200_201_Kalman&ARIMA.csv', index=False)"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
